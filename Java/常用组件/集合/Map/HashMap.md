# HashMap

## 1.存储结构

- hashmap底层是以==数组方式==进行存储。将`key-value`对作为数组中的一个元素进行存储。

  ```java
  static class Node<K,V> implements Map.Entry<K,V> {
          final int hash;
          final K key;
          V value;
          Node<K,V> next;
  }
  ```

- `key-value`都是`Map.Entry`中的属性。其中将 key 的值进行 hash 之后进行存储，即每一个 key 都是计算 hash 值，然后再存储。每一个 Hash 值对应一个数组下标，数组下标是根据 hash 值和数组长度计算得来。

- 由于不同的 key 有可能 hash 值相同，即该位置的数组中的元素出现两个，对于这种情况，hashmap 采用==链表形式==进行存储。

- 下图描述了 hashmap 的存储结构图

<img src="https://raw.githubusercontent.com/Famezyy/picture/master/notePictureBed/SouthEast-b6fad6d78315224694a5ce7a20e6b148-d03332" alt="img" style="zoom: 67%;" />

## 2.和HashTable的不同

**1、线程安全**

两者最主要的区别在于 Hashtable 是线程安全，而 HashMap 则非线程安全。

Hashtable 的实现方法里面都添加了`synchronized`关键字来确保线程同步，因此相对而言性能较差，我们平时使用时若无特殊需求建议使用 HashMap，在多线程环境下若使用HashMap 需要使用`Collections.synchronizedMap()`方法来获取一个线程安全的集合。

> `Collections.synchronizedMap()`实现原理是 Collections 定义了一个 SynchronizedMap 的内部类，这个类实现了 Map 接口，在调用方法时使用`synchronized`来保证线程同步，当然了实际上操作的还是我们传入的 HashMap  实例，简单的说就是`Collections.synchronizedMap()`方法帮我们在操作 HashMap 时自动添加了`synchronized`来实现线程同步，类似的其它Collections.synchronizedXX 方法也是类似原理。
>
> **ConcurrentHashMap**
>
> 容器中有多把锁，每一把锁锁一段数据，这样在多线程访问时不同段的数据时，就不会存在锁竞争了，这 样便可以有效地提高并发效率。这就是 ConcurrentHashMap 所采用的`分段锁`思想。

**2、针对null的不同**

HashMap 可以使用 null 作为 key，而 Hashtable 则不允许 null 作为 key，会直接抛出`NullPointerException`异常。

> HashMap 以 null 作为 key 时，总是存储在 table 数组的第一个节点上（index=0）。

**3、继承结构**

HashMap 是对 Map 接口的实现，HashTable 实现了 Map 接口和 Dictionary 抽象类。

**4、初始容量与扩容**

HashMap 的初始容量为 16，Hashtable 初始容量为 11，两者的填充因子默认都是 0.75。即当当前容量大于`16 * 0.75`时就会发生扩容。

HashMap 扩容时是当前容量翻倍即：capacity\*2，Hashtable 扩容时是容量翻倍 +1 即：capacity\*2+1。

> 给出的扩容因子过高，虽然提升了空间占用，但 hash 冲突比较严重，影响查找效率。过低查找效率高，但空间占用低，0.75 是进行多次试验后的最佳均衡点。

## 3.Hash冲突

HashMap 底层是由数组+链表、红黑树构成的，当通过`put(key, value)`向 hashmap 中添加元素时，需要通过散列函数确定元素究竟应该放在数组中的那个位置，当不同的元素被放置在数组的同一个位置时，后放入的元素会以链表的形式，插在前一个元素的尾部，**链表长度 >=8 时链表转为红黑树**，红黑树是一棵接近于平衡的二叉树，其查询时间复杂度为 O(logn)，远远比链表的查询效率高。这个时候我们称发生了 hash 冲突。

> 发生冲突时，JDK1.7 版本底层为链表，JDK1.8 以后为链表+红黑树。

### 如何解决？

当我们向 hashmap 中 put 元素 (key, value) 时,最终会执行`putVal()`方法，而在`putVal()`方法中，又执行了`hash(key)`这个操作，并将执行结果作为参数传递给了 putVal 方法。

```java
public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

**`(h = key.hashCode()) ^ (h >>> 16)`执行了三步操作:**

1. h = key.hashCode()

这一步会根据 key 值计算出一个 int 类型的 h 值也就是 hashcode 值，例如:

```java
"helloWorld".hashCode() --> -1554135584
"123456".hashCode() --> 1450575459
"我爱java".hashCode() --> -1588929438
```

至于`hashCode()`是如何根据 key 计算出 hashcode 值的，要分几种情况进行分析：

- 如果我们使用的自己创建的对象，在我们没有重写 hashCode() 方法的情况下,会调用 Object 类的 hashCode() 方法，而此时返回就是==对象的内存地址值==，所以如果对象不同，那么通过hashcode() 计算出的 hashcode 就是不同的。

- 如果是使用 java 中定义的引用类型例如 String，Integer 等作为 key，这些类一般都会重写 hashCode() 方法，有兴趣可以翻看一下对应的源码。简单来说，Integer 类的 hashCode() 返回的就是Integer 值，而 String 类型的 hashCode() 方法稍稍复杂一点，这里不做展开。总的来说，hashCode() 方法的作用就是要根据不同的 key 得到不同的 hashCode 值。

2. h >>> 16

这一步将第 1 步计算出的 h 值无符号右移 16 位。

3. h ^ (h >>> 16)

将 hashcode 值的高低 16 位进行异或操作（同0得0、同1得0、不同得1）得到 hash 值，举例说明：

- 假设 h 值为：1290846991
- 它的二进制数为：01001100 11110000 11000011 00001111
- 右移十六位之后：00000000 00000000 01001100 11110000
- 进行异或操作后：01001100 11110000 10001100 11110000
- 最终得到的 hash 值：1290833136


那么问题来了，明明通过第一步得到的 hashcode 值就可以作为 hash 返回，为什么还要要进行第二步和第三步的操作呢？

答案是为了==减少 hash 冲突==！

**元素在数组中存放的位置是由下面这行代码决定的：**

```java
// 将(数组的长度-1)和hash值进行按位与操作:
tab[i = (n - 1) & hash]  // i为数组对应位置的索引，n为当前数组的大小
```

>当数组长度 n 较小时，n-1 的二进制数高 16 位全部为 0，这个时候如果直接和 h 值进行`&`（按位与）操作，那么只能利用到 h 值的低 16 位数据，这个时候会大大增加 hash 冲突发生的可能性，因为不同的 h 值转化为 2 进制后低 16 位是有可能相同的，如上面所举例子中：`key1.hashCode()` 和`key2.hashCode()` 得到的 h 值不同，一个`h1 = 3654061296` ，另一个`h2 = 3652881648`，但是不幸的是这 h1、h2 两个数转化为 2 进制后低 16 位是完全相同的，所以`h1 & (n-1)`和 `h2 & (n-1)` 会计算出相同的结果，这也导致了 node1 和 node2 存储在了数组索引相同的位置，发生了 hash 冲突。
>		
>当我们使用进行 `h ^ (h >>> 16)` 操作时，会将==h的高16位数据和低16位数据进行异或操作==，最终得出的 hash 值的高 16 位保留了 h 值的高 16 位数据，而 hash 值的低 16 数据则是 h 值的高低 16 位数据共同作用的结果。所以即使 h1 和 h2 的低 16 位相同，最终计算出的 hash 值低 16 位也大概率是不同的，降低了 hash 冲突发生的概率。

### 这里面还有一个值的注意的点: 为什么是(n-1)?

要理解这一点，我们首先要知道 HashMap 规定了数组的长度 n 必须为 2 的整数次幂。

HashMap 为了实现存取高效，要尽量减少碰撞，就是要尽量做到：把数据分配均匀，保证每个链表长度大致相同，我们就需要一个算法来实现：将存入的数据保存到那个链表中的算法，而这个算法实际就是取模：`hash%length`，但是，大家都知道这种运算不如位移运算快。因此，源码中做了优化 `hash&(length-1)`。也就是说 `hash%length==hash&(length-1)`。

### 那为什么是2的n次方呢？

因为 2 的 n 次方实际就是 1 后面 n 个 0，而 2 的 n 次方 -1，实际就是 n 个 1。

例如长度为 8 时候，3&(8-1)=3，2&(8-1)=2，不同位置上，不碰撞。而长度为5的时候，3&(5-1)=0，2&(5-1)=0，都在 0 上，出现碰撞了。所以，保证容积是 2 的 n 次方，是为了保证在做 (length-1) 的时候，每一位都能 &1，也就是和 1111......1111111 进行与运算。`即：两位同时为“1”，结果才为“1”，否则为0`，这样可以减少碰撞。

由以上源码第 2 步，`tab[i = (n- 1) & hash]` 中 tab 就是 HashMap 的实体数组，其下边通过 `i = (n - 1) & hash` 来获取(n 表示数组长度，hash 表示 hashCode 值)，但是这必须保证数组长度为2的整数次幂，我们继续往下看。

现在我们可以使用**与运算** `(n-1) & hash` 取代**取模运算** `hash%length`，因为这两种方式记算出来的结果是一致的( n 就是l ength)，也就是 `(length-1)&hash = hash%length`，例如：假设数组长度为 4，哈希值为 10

```java
(n-1) & hash = (4-1) & 10 = 00000011 & 00001010 = 00000010 = 2
hash % length = 10 % 4 = 2
```

但是当数组的长=长度不为 2 的指数次幂时，两种方式计算的结果不一样，即`(length-1)&hash ≠ hash&length`

例如：再假设数组长度为 5，哈希值 10

```java
(n-1) & hash = (5-1) & 10 = 00000100 & 00001010 = 00000000 = 0
hash % length = 10 % 5 = 2
```

**但最重要的一点，是要保证定位出来的值是在数组的长度之内的，不能超出数组长度，并且减少哈希碰撞，让每个位都可能被取到**，我们来看下面例子：

```java
例如：(16-1) & hash
二进制的15：    0000 0000 0000 1111
hash(随机)      1101 0111 1011 0000
hash(随机)      1101 0111 1011 1111
结果                0000 0000 0000 0001 ~ 0000 0000 0000 1111
即得出的索引下标只能在0~15之间，保证了所有索引都在数组长度的范围内而不会越界
并且由于2的指数次幂-1都是...1111的形式的，即最后一位是1
这样，由于hash是随机的，进行与运算后每一位都是能取到的
=============================================================
反例：(7-1) & hash
二进制6：      0000 0000 0000 0110
hash           1011 1001 0101 0000
hash           1001 0001 0000 1111
结果           0000 0000 0000 0000 ~ 0000 0000 0000 0110
即得出的索引范围在0~6，虽然不会越界，但最后一位是0
即现在无论hash为何值，0001，0011，0101这几个值是不可能取到的
这就加剧了hash碰撞，并且浪费了大量数组空间，显然是我们不想看到的
```

> 总结：首先使用位运算来加快计算的效率，而要使用位运算，就需要数组 -1 然后与 hash 值保证其在数组范围内，只有当数组长度为 2 的指数次幂时，其计算得出的值才能和取模算法的值相等，并且保证能取到数组的每一位，减少哈希碰撞，不浪费大量的数组资源！

